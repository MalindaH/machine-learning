{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GhchpEBJPlzD"
   },
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mehHd1-u5FnR"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import sys\n",
    "import os\n",
    "import gc\n",
    "import cv2\n",
    "\n",
    "import csv\n",
    "from google.colab import files\n",
    "from google.colab import drive\n",
    "\n",
    "from scipy.ndimage.interpolation import rotate\n",
    "from scipy.ndimage.interpolation import shift\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, Callback, EarlyStopping\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.layers import GaussianNoise\n",
    "from keras import Model\n",
    "from keras import layers\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Input\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "np.random.seed(121)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MF59sWYcPpe8"
   },
   "source": [
    "Loading files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DCVfX7G95PEL",
    "outputId": "48904ee9-e3db-4b9e-a547-546710e0dc5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "<KeysViewHDF5 ['test_dataset', 'train_dataset', 'train_labels']>\n"
     ]
    }
   ],
   "source": [
    "drive.mount('/content/drive')                   #mount the file\n",
    "os.chdir(\"/content/drive/My Drive\")             #change file directory\n",
    "dataset = h5py.File('MNIST_synthetic.h5', 'r')  #load file\n",
    "print(dataset.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q2l9zPkNPsbH"
   },
   "source": [
    "Extracting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lrre57tr5Qr0"
   },
   "outputs": [],
   "source": [
    "X_train = dataset.get('train_dataset')\n",
    "Y_train = dataset.get('train_labels')\n",
    "Thex_test = dataset.get('test_dataset')\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "Y_train = np.array(Y_train)\n",
    "Thex_test = np.array(Thex_test)         #load file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "baaL7uOOPwbC"
   },
   "source": [
    "Preprocessing, including normalization and using one-hot label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sr_8wJFT5S4n"
   },
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "Thex_test = Thex_test.astype('float32')\n",
    "X_train /= 255\n",
    "Thex_test /= 255\n",
    "Y_train = np_utils.to_categorical(Y_train, 11)   #one hot coding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wvHf5xR1P5CP"
   },
   "source": [
    "Further preprocessing, namely resize to twice (for x_train and x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HxU1V_cP5UgP",
    "outputId": "e496c344-065d-41e5-88a9-adfcbf4b2a89"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56000, 128, 128, 1)\n"
     ]
    }
   ],
   "source": [
    "def image_preprocessing(img, dimx = 64, dimy = 64):\n",
    "    img1 = cv2.resize(img, (dimx, dimy), interpolation = cv2.INTER_LINEAR)   #resize data\n",
    "    img1 = img1[..., np.newaxis]\n",
    "    return img1\n",
    "\n",
    "\n",
    "X_train = np.array([image_preprocessing(i,128,128) for i in X_train])     #preprocessing\n",
    "Thex_test = np.array([image_preprocessing(i,128,128) for i in Thex_test])\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ORwEjZMV7iuk"
   },
   "outputs": [],
   "source": [
    "batchsize = 128    #batchsize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YZR7ZeAWQPK1"
   },
   "source": [
    "Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C8Kle7rv5WKp",
    "outputId": "b46afa24-2532-48e3-e556-eec2ebf08e54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50400, 128, 128, 1)\n",
      "(50400, 5, 11)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(X_train, Y_train, test_size=0.1, random_state=21, shuffle=True)  #split data\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fr1CltXeQRqo"
   },
   "source": [
    "Generate more image data based on x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IPFNmwms5Yml"
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=10,         #rotation range\n",
    "    shear_range=0.1,           #shear range\n",
    "    zoom_range=0.1)            #zoom range\n",
    "\n",
    "Train = datagen.flow(x_train, y_train, batch_size=batchsize, seed=20)    #generate random training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lmFTHiExQWd6"
   },
   "source": [
    "put x_train into model.fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dr5Y_k-F5e2v"
   },
   "outputs": [],
   "source": [
    "def data_augmentor(data_gen):\n",
    "    for x, y in data_gen:\n",
    "        y = [y[:, i] for i in range(5)]    #select each\n",
    "        yield x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jgo6Cb8vQmL1"
   },
   "source": [
    "Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SX4vG9LN5hvP"
   },
   "outputs": [],
   "source": [
    "def cnn_model(input_dim=(128, 128, 1), out_dim=11):    #input dim = 128,128, outdim = 11\n",
    "    inputss = Input(shape=input_dim)\n",
    "\n",
    "    x = BatchNormalization()(inputss)      #batch normalization\n",
    "    x = Dropout(.1)(x)                     #dropout\n",
    "    x = GaussianNoise(0.1)(x)              #gaussian noise\n",
    "    x = Conv2D(32, (3,3), activation='relu', padding='same')(x)          #convolutional layer(size=32, activation is relu)\n",
    "    x = Conv2D(32, (3,3), activation='relu', padding='same')(x)\n",
    "    x = MaxPooling2D(pool_size=(2,2))(x)  \n",
    "    x = Dropout(.25)(x)\n",
    "\n",
    "    x = BatchNormalization()(x)  \n",
    "    x = Conv2D(64, (3,3), activation='relu', padding='same')(x)          #convolutional layer(size=64, activation is relu)\n",
    "    x = Conv2D(64, (3,3), activation='relu', padding='same')(x)\n",
    "    x = MaxPooling2D(pool_size=(2,2))(x)      \n",
    "    x = Dropout(.25)(x)\n",
    "\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(128, (3,3), activation='relu', padding='same')(x)         #convolutional layer(size=128, activation is relu)\n",
    "    x = Conv2D(128, (3,3), activation='relu', padding='same')(x)    \n",
    "    x = Conv2D(128, (3,3), activation='relu', padding='same')(x)  \n",
    "    x = Conv2D(128, (3,3), activation='relu', padding='same')(x)   \n",
    "    x = MaxPooling2D(pool_size=(2,2))(x) \n",
    "    x = Dropout(.25)(x) \n",
    "\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(256, (3,3), activation='relu', padding='same')(x)         #convolutional layer(size=256, activation is relu)\n",
    "    x = Conv2D(256, (3,3), activation='relu', padding='same')(x)    \n",
    "    x = Conv2D(256, (3,3), activation='relu', padding='same')(x)  \n",
    "    x = Conv2D(256, (3,3), activation='relu', padding='same')(x)  \n",
    "    x = MaxPooling2D(pool_size=(2,2))(x)  \n",
    "    x = Dropout(.25)(x) \n",
    "    x = GaussianNoise(0.05)(x)\n",
    "\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Flatten()(x)                                 #flatten 2D to vectorize\n",
    "    x = Dense(512,activation='relu')(x)              #dense layer\n",
    "    x = Dropout(.5)(x)                               #dropout\n",
    "    x = Dense(512,activation='relu')(x)\n",
    "    x = Dropout(.5)(x)\n",
    "    x = GaussianNoise(0.05)(x)\n",
    "    outputss = [Dense(11, activation='softmax', name=f\"digit_{i}\")(x) for i in range(5)]    #output softmax\n",
    "    \n",
    "    model = Model(inputs=inputss, outputs=outputss)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])  #compile model, using cross entropy\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-2rdGvtLQrPe"
   },
   "source": [
    "some callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EyXKGZ5qHXC5"
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(             #early stopping\n",
    "\tmonitor = \"val_loss\",                     #monitor validation loss\n",
    "\tpatience = 10,\n",
    "\tverbose = 1,\n",
    "\trestore_best_weights = True\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.3, min_delta=0.00001,\n",
    "                              patience=6, verbose=1)     #reduce learning rate on plateau\n",
    "\n",
    "checkpoint_filepath = '/content/drive/My Drive/checkpoints2/weights.{epoch:02d}.h5'\n",
    "model_checkpoint_callback = ModelCheckpoint(   #model check point\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='auto',\n",
    "    #save_best_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9HmNqjtXQ21X"
   },
   "source": [
    "training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qka1jHnX5jn5",
    "outputId": "5a95e3e3-b5af-47f2-8eb9-8d56a6d4a4d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "   2/2800 [..............................] - ETA: 3:01 - loss: 19.8887 - digit_0_loss: 4.9431 - digit_1_loss: 4.7107 - digit_2_loss: 3.5821 - digit_3_loss: 3.2504 - digit_4_loss: 3.4024 - digit_0_accuracy: 0.0625 - digit_1_accuracy: 0.0742 - digit_2_accuracy: 0.2422 - digit_3_accuracy: 0.3281 - digit_4_accuracy: 0.4062WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0460s vs `on_train_batch_end` time: 0.0835s). Check your callbacks.\n",
      "2800/2800 [==============================] - 393s 140ms/step - loss: 5.0650 - digit_0_loss: 1.4212 - digit_1_loss: 1.2698 - digit_2_loss: 1.0561 - digit_3_loss: 0.8083 - digit_4_loss: 0.5096 - digit_0_accuracy: 0.4766 - digit_1_accuracy: 0.5302 - digit_2_accuracy: 0.6092 - digit_3_accuracy: 0.7048 - digit_4_accuracy: 0.8197 - val_loss: 0.4951 - val_digit_0_loss: 0.1050 - val_digit_1_loss: 0.1269 - val_digit_2_loss: 0.1176 - val_digit_3_loss: 0.0755 - val_digit_4_loss: 0.0701 - val_digit_0_accuracy: 0.9805 - val_digit_1_accuracy: 0.9812 - val_digit_2_accuracy: 0.9812 - val_digit_3_accuracy: 0.9886 - val_digit_4_accuracy: 0.9862\n",
      "Epoch 2/60\n",
      "2800/2800 [==============================] - 391s 140ms/step - loss: 0.8045 - digit_0_loss: 0.2086 - digit_1_loss: 0.1960 - digit_2_loss: 0.1643 - digit_3_loss: 0.1335 - digit_4_loss: 0.1020 - digit_0_accuracy: 0.9452 - digit_1_accuracy: 0.9455 - digit_2_accuracy: 0.9523 - digit_3_accuracy: 0.9602 - digit_4_accuracy: 0.9688 - val_loss: 0.1478 - val_digit_0_loss: 0.0347 - val_digit_1_loss: 0.0348 - val_digit_2_loss: 0.0435 - val_digit_3_loss: 0.0200 - val_digit_4_loss: 0.0147 - val_digit_0_accuracy: 0.9918 - val_digit_1_accuracy: 0.9939 - val_digit_2_accuracy: 0.9927 - val_digit_3_accuracy: 0.9962 - val_digit_4_accuracy: 0.9975\n",
      "Epoch 3/60\n",
      "2800/2800 [==============================] - 390s 139ms/step - loss: 0.3495 - digit_0_loss: 0.0984 - digit_1_loss: 0.0847 - digit_2_loss: 0.0702 - digit_3_loss: 0.0566 - digit_4_loss: 0.0396 - digit_0_accuracy: 0.9772 - digit_1_accuracy: 0.9788 - digit_2_accuracy: 0.9819 - digit_3_accuracy: 0.9848 - digit_4_accuracy: 0.9884 - val_loss: 0.0948 - val_digit_0_loss: 0.0286 - val_digit_1_loss: 0.0255 - val_digit_2_loss: 0.0238 - val_digit_3_loss: 0.0097 - val_digit_4_loss: 0.0072 - val_digit_0_accuracy: 0.9946 - val_digit_1_accuracy: 0.9959 - val_digit_2_accuracy: 0.9955 - val_digit_3_accuracy: 0.9979 - val_digit_4_accuracy: 0.9987\n",
      "Epoch 4/60\n",
      "2800/2800 [==============================] - 389s 139ms/step - loss: 0.2526 - digit_0_loss: 0.0734 - digit_1_loss: 0.0601 - digit_2_loss: 0.0515 - digit_3_loss: 0.0402 - digit_4_loss: 0.0275 - digit_0_accuracy: 0.9830 - digit_1_accuracy: 0.9857 - digit_2_accuracy: 0.9870 - digit_3_accuracy: 0.9896 - digit_4_accuracy: 0.9921 - val_loss: 0.0679 - val_digit_0_loss: 0.0092 - val_digit_1_loss: 0.0291 - val_digit_2_loss: 0.0147 - val_digit_3_loss: 0.0077 - val_digit_4_loss: 0.0071 - val_digit_0_accuracy: 0.9984 - val_digit_1_accuracy: 0.9968 - val_digit_2_accuracy: 0.9979 - val_digit_3_accuracy: 0.9984 - val_digit_4_accuracy: 0.9995\n",
      "Epoch 5/60\n",
      "2800/2800 [==============================] - 391s 140ms/step - loss: 0.2016 - digit_0_loss: 0.0574 - digit_1_loss: 0.0488 - digit_2_loss: 0.0401 - digit_3_loss: 0.0326 - digit_4_loss: 0.0227 - digit_0_accuracy: 0.9868 - digit_1_accuracy: 0.9883 - digit_2_accuracy: 0.9900 - digit_3_accuracy: 0.9919 - digit_4_accuracy: 0.9937 - val_loss: 0.0680 - val_digit_0_loss: 0.0133 - val_digit_1_loss: 0.0180 - val_digit_2_loss: 0.0243 - val_digit_3_loss: 0.0061 - val_digit_4_loss: 0.0062 - val_digit_0_accuracy: 0.9977 - val_digit_1_accuracy: 0.9973 - val_digit_2_accuracy: 0.9966 - val_digit_3_accuracy: 0.9987 - val_digit_4_accuracy: 0.9995\n",
      "Epoch 6/60\n",
      "2800/2800 [==============================] - 390s 139ms/step - loss: 0.1748 - digit_0_loss: 0.0504 - digit_1_loss: 0.0426 - digit_2_loss: 0.0350 - digit_3_loss: 0.0275 - digit_4_loss: 0.0192 - digit_0_accuracy: 0.9884 - digit_1_accuracy: 0.9900 - digit_2_accuracy: 0.9913 - digit_3_accuracy: 0.9930 - digit_4_accuracy: 0.9947 - val_loss: 0.0683 - val_digit_0_loss: 0.0170 - val_digit_1_loss: 0.0216 - val_digit_2_loss: 0.0201 - val_digit_3_loss: 0.0061 - val_digit_4_loss: 0.0035 - val_digit_0_accuracy: 0.9977 - val_digit_1_accuracy: 0.9973 - val_digit_2_accuracy: 0.9980 - val_digit_3_accuracy: 0.9986 - val_digit_4_accuracy: 0.9995\n",
      "Epoch 7/60\n",
      "2800/2800 [==============================] - 390s 139ms/step - loss: 0.1579 - digit_0_loss: 0.0464 - digit_1_loss: 0.0369 - digit_2_loss: 0.0321 - digit_3_loss: 0.0253 - digit_4_loss: 0.0172 - digit_0_accuracy: 0.9895 - digit_1_accuracy: 0.9912 - digit_2_accuracy: 0.9923 - digit_3_accuracy: 0.9939 - digit_4_accuracy: 0.9955 - val_loss: 0.0738 - val_digit_0_loss: 0.0123 - val_digit_1_loss: 0.0237 - val_digit_2_loss: 0.0223 - val_digit_3_loss: 0.0098 - val_digit_4_loss: 0.0057 - val_digit_0_accuracy: 0.9971 - val_digit_1_accuracy: 0.9970 - val_digit_2_accuracy: 0.9966 - val_digit_3_accuracy: 0.9984 - val_digit_4_accuracy: 0.9993\n",
      "Epoch 8/60\n",
      "2800/2800 [==============================] - 392s 140ms/step - loss: 0.1435 - digit_0_loss: 0.0409 - digit_1_loss: 0.0338 - digit_2_loss: 0.0289 - digit_3_loss: 0.0236 - digit_4_loss: 0.0163 - digit_0_accuracy: 0.9906 - digit_1_accuracy: 0.9921 - digit_2_accuracy: 0.9930 - digit_3_accuracy: 0.9941 - digit_4_accuracy: 0.9958 - val_loss: 0.0583 - val_digit_0_loss: 0.0089 - val_digit_1_loss: 0.0220 - val_digit_2_loss: 0.0203 - val_digit_3_loss: 0.0026 - val_digit_4_loss: 0.0045 - val_digit_0_accuracy: 0.9982 - val_digit_1_accuracy: 0.9982 - val_digit_2_accuracy: 0.9979 - val_digit_3_accuracy: 0.9995 - val_digit_4_accuracy: 0.9991\n",
      "Epoch 9/60\n",
      "2800/2800 [==============================] - 391s 140ms/step - loss: 0.1371 - digit_0_loss: 0.0409 - digit_1_loss: 0.0318 - digit_2_loss: 0.0272 - digit_3_loss: 0.0213 - digit_4_loss: 0.0158 - digit_0_accuracy: 0.9911 - digit_1_accuracy: 0.9926 - digit_2_accuracy: 0.9933 - digit_3_accuracy: 0.9947 - digit_4_accuracy: 0.9960 - val_loss: 0.0477 - val_digit_0_loss: 0.0072 - val_digit_1_loss: 0.0185 - val_digit_2_loss: 0.0145 - val_digit_3_loss: 0.0043 - val_digit_4_loss: 0.0031 - val_digit_0_accuracy: 0.9984 - val_digit_1_accuracy: 0.9980 - val_digit_2_accuracy: 0.9982 - val_digit_3_accuracy: 0.9991 - val_digit_4_accuracy: 0.9993\n",
      "Epoch 10/60\n",
      "2800/2800 [==============================] - 390s 139ms/step - loss: 0.1287 - digit_0_loss: 0.0381 - digit_1_loss: 0.0295 - digit_2_loss: 0.0255 - digit_3_loss: 0.0204 - digit_4_loss: 0.0152 - digit_0_accuracy: 0.9914 - digit_1_accuracy: 0.9931 - digit_2_accuracy: 0.9939 - digit_3_accuracy: 0.9950 - digit_4_accuracy: 0.9962 - val_loss: 0.0629 - val_digit_0_loss: 0.0088 - val_digit_1_loss: 0.0247 - val_digit_2_loss: 0.0214 - val_digit_3_loss: 0.0048 - val_digit_4_loss: 0.0032 - val_digit_0_accuracy: 0.9982 - val_digit_1_accuracy: 0.9975 - val_digit_2_accuracy: 0.9979 - val_digit_3_accuracy: 0.9993 - val_digit_4_accuracy: 0.9993\n",
      "Epoch 11/60\n",
      "2800/2800 [==============================] - 389s 139ms/step - loss: 0.1261 - digit_0_loss: 0.0361 - digit_1_loss: 0.0295 - digit_2_loss: 0.0256 - digit_3_loss: 0.0208 - digit_4_loss: 0.0142 - digit_0_accuracy: 0.9918 - digit_1_accuracy: 0.9932 - digit_2_accuracy: 0.9940 - digit_3_accuracy: 0.9952 - digit_4_accuracy: 0.9965 - val_loss: 0.0645 - val_digit_0_loss: 0.0053 - val_digit_1_loss: 0.0344 - val_digit_2_loss: 0.0174 - val_digit_3_loss: 0.0033 - val_digit_4_loss: 0.0041 - val_digit_0_accuracy: 0.9989 - val_digit_1_accuracy: 0.9982 - val_digit_2_accuracy: 0.9989 - val_digit_3_accuracy: 0.9991 - val_digit_4_accuracy: 0.9996\n",
      "Epoch 12/60\n",
      "2800/2800 [==============================] - 389s 139ms/step - loss: 0.1222 - digit_0_loss: 0.0358 - digit_1_loss: 0.0288 - digit_2_loss: 0.0245 - digit_3_loss: 0.0193 - digit_4_loss: 0.0137 - digit_0_accuracy: 0.9923 - digit_1_accuracy: 0.9936 - digit_2_accuracy: 0.9943 - digit_3_accuracy: 0.9956 - digit_4_accuracy: 0.9967 - val_loss: 0.0584 - val_digit_0_loss: 0.0094 - val_digit_1_loss: 0.0230 - val_digit_2_loss: 0.0135 - val_digit_3_loss: 0.0037 - val_digit_4_loss: 0.0087 - val_digit_0_accuracy: 0.9980 - val_digit_1_accuracy: 0.9966 - val_digit_2_accuracy: 0.9984 - val_digit_3_accuracy: 0.9989 - val_digit_4_accuracy: 0.9991\n",
      "Epoch 13/60\n",
      "2800/2800 [==============================] - 388s 138ms/step - loss: 0.1190 - digit_0_loss: 0.0327 - digit_1_loss: 0.0284 - digit_2_loss: 0.0240 - digit_3_loss: 0.0195 - digit_4_loss: 0.0144 - digit_0_accuracy: 0.9926 - digit_1_accuracy: 0.9937 - digit_2_accuracy: 0.9945 - digit_3_accuracy: 0.9955 - digit_4_accuracy: 0.9968 - val_loss: 0.0647 - val_digit_0_loss: 0.0068 - val_digit_1_loss: 0.0238 - val_digit_2_loss: 0.0193 - val_digit_3_loss: 0.0075 - val_digit_4_loss: 0.0074 - val_digit_0_accuracy: 0.9987 - val_digit_1_accuracy: 0.9982 - val_digit_2_accuracy: 0.9982 - val_digit_3_accuracy: 0.9995 - val_digit_4_accuracy: 0.9991\n",
      "Epoch 14/60\n",
      "2800/2800 [==============================] - 388s 138ms/step - loss: 0.1182 - digit_0_loss: 0.0336 - digit_1_loss: 0.0273 - digit_2_loss: 0.0244 - digit_3_loss: 0.0189 - digit_4_loss: 0.0140 - digit_0_accuracy: 0.9926 - digit_1_accuracy: 0.9939 - digit_2_accuracy: 0.9946 - digit_3_accuracy: 0.9956 - digit_4_accuracy: 0.9968 - val_loss: 0.0529 - val_digit_0_loss: 0.0097 - val_digit_1_loss: 0.0176 - val_digit_2_loss: 0.0200 - val_digit_3_loss: 0.0032 - val_digit_4_loss: 0.0024 - val_digit_0_accuracy: 0.9982 - val_digit_1_accuracy: 0.9975 - val_digit_2_accuracy: 0.9977 - val_digit_3_accuracy: 0.9996 - val_digit_4_accuracy: 0.9995\n",
      "Epoch 15/60\n",
      "2800/2800 [==============================] - ETA: 0s - loss: 0.1130 - digit_0_loss: 0.0317 - digit_1_loss: 0.0262 - digit_2_loss: 0.0226 - digit_3_loss: 0.0190 - digit_4_loss: 0.0135 - digit_0_accuracy: 0.9930 - digit_1_accuracy: 0.9943 - digit_2_accuracy: 0.9950 - digit_3_accuracy: 0.9959 - digit_4_accuracy: 0.9970\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
      "2800/2800 [==============================] - 389s 139ms/step - loss: 0.1130 - digit_0_loss: 0.0317 - digit_1_loss: 0.0262 - digit_2_loss: 0.0226 - digit_3_loss: 0.0190 - digit_4_loss: 0.0135 - digit_0_accuracy: 0.9930 - digit_1_accuracy: 0.9943 - digit_2_accuracy: 0.9950 - digit_3_accuracy: 0.9959 - digit_4_accuracy: 0.9970 - val_loss: 0.0805 - val_digit_0_loss: 0.0098 - val_digit_1_loss: 0.0390 - val_digit_2_loss: 0.0199 - val_digit_3_loss: 0.0061 - val_digit_4_loss: 0.0057 - val_digit_0_accuracy: 0.9973 - val_digit_1_accuracy: 0.9986 - val_digit_2_accuracy: 0.9986 - val_digit_3_accuracy: 0.9991 - val_digit_4_accuracy: 0.9995\n",
      "Epoch 16/60\n",
      "2800/2800 [==============================] - 388s 139ms/step - loss: 0.0510 - digit_0_loss: 0.0157 - digit_1_loss: 0.0115 - digit_2_loss: 0.0098 - digit_3_loss: 0.0085 - digit_4_loss: 0.0056 - digit_0_accuracy: 0.9963 - digit_1_accuracy: 0.9972 - digit_2_accuracy: 0.9977 - digit_3_accuracy: 0.9981 - digit_4_accuracy: 0.9986 - val_loss: 0.0482 - val_digit_0_loss: 0.0039 - val_digit_1_loss: 0.0213 - val_digit_2_loss: 0.0206 - val_digit_3_loss: 0.0017 - val_digit_4_loss: 7.0965e-04 - val_digit_0_accuracy: 0.9995 - val_digit_1_accuracy: 0.9987 - val_digit_2_accuracy: 0.9989 - val_digit_3_accuracy: 0.9998 - val_digit_4_accuracy: 0.9998\n",
      "Epoch 17/60\n",
      "2800/2800 [==============================] - 388s 139ms/step - loss: 0.0379 - digit_0_loss: 0.0123 - digit_1_loss: 0.0086 - digit_2_loss: 0.0073 - digit_3_loss: 0.0057 - digit_4_loss: 0.0040 - digit_0_accuracy: 0.9971 - digit_1_accuracy: 0.9979 - digit_2_accuracy: 0.9982 - digit_3_accuracy: 0.9986 - digit_4_accuracy: 0.9989 - val_loss: 0.0488 - val_digit_0_loss: 0.0050 - val_digit_1_loss: 0.0198 - val_digit_2_loss: 0.0220 - val_digit_3_loss: 0.0013 - val_digit_4_loss: 6.0916e-04 - val_digit_0_accuracy: 0.9993 - val_digit_1_accuracy: 0.9986 - val_digit_2_accuracy: 0.9991 - val_digit_3_accuracy: 0.9998 - val_digit_4_accuracy: 0.9996\n",
      "Epoch 18/60\n",
      "2800/2800 [==============================] - 387s 138ms/step - loss: 0.0362 - digit_0_loss: 0.0109 - digit_1_loss: 0.0086 - digit_2_loss: 0.0070 - digit_3_loss: 0.0056 - digit_4_loss: 0.0041 - digit_0_accuracy: 0.9974 - digit_1_accuracy: 0.9980 - digit_2_accuracy: 0.9983 - digit_3_accuracy: 0.9987 - digit_4_accuracy: 0.9990 - val_loss: 0.0499 - val_digit_0_loss: 0.0036 - val_digit_1_loss: 0.0195 - val_digit_2_loss: 0.0230 - val_digit_3_loss: 0.0012 - val_digit_4_loss: 0.0026 - val_digit_0_accuracy: 0.9995 - val_digit_1_accuracy: 0.9986 - val_digit_2_accuracy: 0.9989 - val_digit_3_accuracy: 0.9995 - val_digit_4_accuracy: 0.9996\n",
      "Epoch 19/60\n",
      "2800/2800 [==============================] - 386s 138ms/step - loss: 0.0325 - digit_0_loss: 0.0095 - digit_1_loss: 0.0079 - digit_2_loss: 0.0059 - digit_3_loss: 0.0055 - digit_4_loss: 0.0038 - digit_0_accuracy: 0.9977 - digit_1_accuracy: 0.9982 - digit_2_accuracy: 0.9985 - digit_3_accuracy: 0.9987 - digit_4_accuracy: 0.9990 - val_loss: 0.0508 - val_digit_0_loss: 0.0043 - val_digit_1_loss: 0.0184 - val_digit_2_loss: 0.0250 - val_digit_3_loss: 0.0030 - val_digit_4_loss: 7.4709e-05 - val_digit_0_accuracy: 0.9995 - val_digit_1_accuracy: 0.9989 - val_digit_2_accuracy: 0.9991 - val_digit_3_accuracy: 0.9995 - val_digit_4_accuracy: 1.0000\n",
      "Epoch 20/60\n",
      "2800/2800 [==============================] - 389s 139ms/step - loss: 0.0320 - digit_0_loss: 0.0098 - digit_1_loss: 0.0074 - digit_2_loss: 0.0056 - digit_3_loss: 0.0054 - digit_4_loss: 0.0037 - digit_0_accuracy: 0.9975 - digit_1_accuracy: 0.9982 - digit_2_accuracy: 0.9986 - digit_3_accuracy: 0.9987 - digit_4_accuracy: 0.9992 - val_loss: 0.0485 - val_digit_0_loss: 0.0038 - val_digit_1_loss: 0.0218 - val_digit_2_loss: 0.0200 - val_digit_3_loss: 0.0013 - val_digit_4_loss: 0.0016 - val_digit_0_accuracy: 0.9996 - val_digit_1_accuracy: 0.9987 - val_digit_2_accuracy: 0.9993 - val_digit_3_accuracy: 0.9996 - val_digit_4_accuracy: 0.9996\n",
      "Epoch 21/60\n",
      "2800/2800 [==============================] - 388s 138ms/step - loss: 0.0298 - digit_0_loss: 0.0094 - digit_1_loss: 0.0066 - digit_2_loss: 0.0059 - digit_3_loss: 0.0048 - digit_4_loss: 0.0031 - digit_0_accuracy: 0.9979 - digit_1_accuracy: 0.9984 - digit_2_accuracy: 0.9985 - digit_3_accuracy: 0.9988 - digit_4_accuracy: 0.9992 - val_loss: 0.0415 - val_digit_0_loss: 0.0038 - val_digit_1_loss: 0.0148 - val_digit_2_loss: 0.0213 - val_digit_3_loss: 0.0016 - val_digit_4_loss: 1.3386e-05 - val_digit_0_accuracy: 0.9995 - val_digit_1_accuracy: 0.9989 - val_digit_2_accuracy: 0.9991 - val_digit_3_accuracy: 0.9998 - val_digit_4_accuracy: 1.0000\n",
      "Epoch 22/60\n",
      "2800/2800 [==============================] - 386s 138ms/step - loss: 0.0289 - digit_0_loss: 0.0089 - digit_1_loss: 0.0067 - digit_2_loss: 0.0053 - digit_3_loss: 0.0047 - digit_4_loss: 0.0032 - digit_0_accuracy: 0.9979 - digit_1_accuracy: 0.9984 - digit_2_accuracy: 0.9987 - digit_3_accuracy: 0.9989 - digit_4_accuracy: 0.9992 - val_loss: 0.0491 - val_digit_0_loss: 0.0029 - val_digit_1_loss: 0.0214 - val_digit_2_loss: 0.0238 - val_digit_3_loss: 8.7145e-04 - val_digit_4_loss: 1.6769e-06 - val_digit_0_accuracy: 0.9998 - val_digit_1_accuracy: 0.9991 - val_digit_2_accuracy: 0.9991 - val_digit_3_accuracy: 0.9998 - val_digit_4_accuracy: 1.0000\n",
      "Epoch 23/60\n",
      "2800/2800 [==============================] - 386s 138ms/step - loss: 0.0281 - digit_0_loss: 0.0087 - digit_1_loss: 0.0067 - digit_2_loss: 0.0051 - digit_3_loss: 0.0041 - digit_4_loss: 0.0034 - digit_0_accuracy: 0.9979 - digit_1_accuracy: 0.9985 - digit_2_accuracy: 0.9988 - digit_3_accuracy: 0.9990 - digit_4_accuracy: 0.9992 - val_loss: 0.0433 - val_digit_0_loss: 0.0031 - val_digit_1_loss: 0.0145 - val_digit_2_loss: 0.0236 - val_digit_3_loss: 0.0021 - val_digit_4_loss: 8.0704e-06 - val_digit_0_accuracy: 0.9998 - val_digit_1_accuracy: 0.9989 - val_digit_2_accuracy: 0.9991 - val_digit_3_accuracy: 0.9996 - val_digit_4_accuracy: 1.0000\n",
      "Epoch 24/60\n",
      "2800/2800 [==============================] - 394s 141ms/step - loss: 0.0259 - digit_0_loss: 0.0076 - digit_1_loss: 0.0065 - digit_2_loss: 0.0047 - digit_3_loss: 0.0045 - digit_4_loss: 0.0026 - digit_0_accuracy: 0.9982 - digit_1_accuracy: 0.9985 - digit_2_accuracy: 0.9988 - digit_3_accuracy: 0.9989 - digit_4_accuracy: 0.9993 - val_loss: 0.0446 - val_digit_0_loss: 0.0034 - val_digit_1_loss: 0.0125 - val_digit_2_loss: 0.0284 - val_digit_3_loss: 2.7045e-04 - val_digit_4_loss: 7.6557e-06 - val_digit_0_accuracy: 0.9996 - val_digit_1_accuracy: 0.9991 - val_digit_2_accuracy: 0.9991 - val_digit_3_accuracy: 0.9998 - val_digit_4_accuracy: 1.0000\n",
      "Epoch 25/60\n",
      "2800/2800 [==============================] - 390s 139ms/step - loss: 0.0263 - digit_0_loss: 0.0079 - digit_1_loss: 0.0061 - digit_2_loss: 0.0053 - digit_3_loss: 0.0039 - digit_4_loss: 0.0031 - digit_0_accuracy: 0.9981 - digit_1_accuracy: 0.9986 - digit_2_accuracy: 0.9988 - digit_3_accuracy: 0.9990 - digit_4_accuracy: 0.9993 - val_loss: 0.0526 - val_digit_0_loss: 0.0033 - val_digit_1_loss: 0.0169 - val_digit_2_loss: 0.0308 - val_digit_3_loss: 0.0016 - val_digit_4_loss: 1.1644e-08 - val_digit_0_accuracy: 0.9995 - val_digit_1_accuracy: 0.9991 - val_digit_2_accuracy: 0.9991 - val_digit_3_accuracy: 0.9998 - val_digit_4_accuracy: 1.0000\n",
      "Epoch 26/60\n",
      "2800/2800 [==============================] - 389s 139ms/step - loss: 0.0253 - digit_0_loss: 0.0078 - digit_1_loss: 0.0056 - digit_2_loss: 0.0047 - digit_3_loss: 0.0043 - digit_4_loss: 0.0028 - digit_0_accuracy: 0.9980 - digit_1_accuracy: 0.9987 - digit_2_accuracy: 0.9988 - digit_3_accuracy: 0.9989 - digit_4_accuracy: 0.9993 - val_loss: 0.0555 - val_digit_0_loss: 0.0027 - val_digit_1_loss: 0.0241 - val_digit_2_loss: 0.0283 - val_digit_3_loss: 3.4145e-04 - val_digit_4_loss: 8.7374e-08 - val_digit_0_accuracy: 0.9998 - val_digit_1_accuracy: 0.9986 - val_digit_2_accuracy: 0.9989 - val_digit_3_accuracy: 0.9998 - val_digit_4_accuracy: 1.0000\n",
      "Epoch 27/60\n",
      "2800/2800 [==============================] - ETA: 0s - loss: 0.0259 - digit_0_loss: 0.0077 - digit_1_loss: 0.0055 - digit_2_loss: 0.0050 - digit_3_loss: 0.0044 - digit_4_loss: 0.0033 - digit_0_accuracy: 0.9981 - digit_1_accuracy: 0.9987 - digit_2_accuracy: 0.9988 - digit_3_accuracy: 0.9990 - digit_4_accuracy: 0.9992\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
      "2800/2800 [==============================] - 388s 139ms/step - loss: 0.0259 - digit_0_loss: 0.0077 - digit_1_loss: 0.0055 - digit_2_loss: 0.0050 - digit_3_loss: 0.0044 - digit_4_loss: 0.0033 - digit_0_accuracy: 0.9981 - digit_1_accuracy: 0.9987 - digit_2_accuracy: 0.9988 - digit_3_accuracy: 0.9990 - digit_4_accuracy: 0.9992 - val_loss: 0.0498 - val_digit_0_loss: 0.0032 - val_digit_1_loss: 0.0174 - val_digit_2_loss: 0.0290 - val_digit_3_loss: 2.4278e-04 - val_digit_4_loss: 9.6961e-07 - val_digit_0_accuracy: 0.9998 - val_digit_1_accuracy: 0.9989 - val_digit_2_accuracy: 0.9991 - val_digit_3_accuracy: 0.9998 - val_digit_4_accuracy: 1.0000\n",
      "Epoch 28/60\n",
      "2800/2800 [==============================] - 389s 139ms/step - loss: 0.0175 - digit_0_loss: 0.0058 - digit_1_loss: 0.0041 - digit_2_loss: 0.0031 - digit_3_loss: 0.0026 - digit_4_loss: 0.0018 - digit_0_accuracy: 0.9986 - digit_1_accuracy: 0.9990 - digit_2_accuracy: 0.9992 - digit_3_accuracy: 0.9993 - digit_4_accuracy: 0.9995 - val_loss: 0.0410 - val_digit_0_loss: 0.0033 - val_digit_1_loss: 0.0115 - val_digit_2_loss: 0.0256 - val_digit_3_loss: 5.4406e-04 - val_digit_4_loss: 3.9806e-08 - val_digit_0_accuracy: 0.9998 - val_digit_1_accuracy: 0.9991 - val_digit_2_accuracy: 0.9991 - val_digit_3_accuracy: 0.9998 - val_digit_4_accuracy: 1.0000\n",
      "Epoch 29/60\n",
      "2800/2800 [==============================] - 389s 139ms/step - loss: 0.0140 - digit_0_loss: 0.0046 - digit_1_loss: 0.0032 - digit_2_loss: 0.0025 - digit_3_loss: 0.0021 - digit_4_loss: 0.0016 - digit_0_accuracy: 0.9988 - digit_1_accuracy: 0.9992 - digit_2_accuracy: 0.9994 - digit_3_accuracy: 0.9994 - digit_4_accuracy: 0.9996 - val_loss: 0.0498 - val_digit_0_loss: 0.0036 - val_digit_1_loss: 0.0151 - val_digit_2_loss: 0.0305 - val_digit_3_loss: 6.5391e-04 - val_digit_4_loss: 1.9797e-09 - val_digit_0_accuracy: 0.9998 - val_digit_1_accuracy: 0.9987 - val_digit_2_accuracy: 0.9991 - val_digit_3_accuracy: 0.9998 - val_digit_4_accuracy: 1.0000\n",
      "Epoch 30/60\n",
      "2800/2800 [==============================] - 388s 138ms/step - loss: 0.0136 - digit_0_loss: 0.0043 - digit_1_loss: 0.0028 - digit_2_loss: 0.0028 - digit_3_loss: 0.0021 - digit_4_loss: 0.0016 - digit_0_accuracy: 0.9990 - digit_1_accuracy: 0.9993 - digit_2_accuracy: 0.9993 - digit_3_accuracy: 0.9995 - digit_4_accuracy: 0.9996 - val_loss: 0.0431 - val_digit_0_loss: 0.0032 - val_digit_1_loss: 0.0151 - val_digit_2_loss: 0.0245 - val_digit_3_loss: 3.3010e-04 - val_digit_4_loss: 1.9462e-07 - val_digit_0_accuracy: 0.9996 - val_digit_1_accuracy: 0.9991 - val_digit_2_accuracy: 0.9991 - val_digit_3_accuracy: 0.9998 - val_digit_4_accuracy: 1.0000\n",
      "Epoch 31/60\n",
      "2800/2800 [==============================] - 387s 138ms/step - loss: 0.0135 - digit_0_loss: 0.0043 - digit_1_loss: 0.0031 - digit_2_loss: 0.0027 - digit_3_loss: 0.0020 - digit_4_loss: 0.0014 - digit_0_accuracy: 0.9989 - digit_1_accuracy: 0.9993 - digit_2_accuracy: 0.9994 - digit_3_accuracy: 0.9995 - digit_4_accuracy: 0.9996 - val_loss: 0.0482 - val_digit_0_loss: 0.0032 - val_digit_1_loss: 0.0191 - val_digit_2_loss: 0.0256 - val_digit_3_loss: 3.0736e-04 - val_digit_4_loss: 1.3792e-06 - val_digit_0_accuracy: 0.9998 - val_digit_1_accuracy: 0.9989 - val_digit_2_accuracy: 0.9989 - val_digit_3_accuracy: 0.9998 - val_digit_4_accuracy: 1.0000\n",
      "Epoch 32/60\n",
      "2800/2800 [==============================] - 386s 138ms/step - loss: 0.0124 - digit_0_loss: 0.0038 - digit_1_loss: 0.0026 - digit_2_loss: 0.0025 - digit_3_loss: 0.0020 - digit_4_loss: 0.0016 - digit_0_accuracy: 0.9990 - digit_1_accuracy: 0.9993 - digit_2_accuracy: 0.9994 - digit_3_accuracy: 0.9995 - digit_4_accuracy: 0.9996 - val_loss: 0.0401 - val_digit_0_loss: 0.0031 - val_digit_1_loss: 0.0128 - val_digit_2_loss: 0.0239 - val_digit_3_loss: 3.7092e-04 - val_digit_4_loss: 3.3513e-07 - val_digit_0_accuracy: 0.9998 - val_digit_1_accuracy: 0.9987 - val_digit_2_accuracy: 0.9993 - val_digit_3_accuracy: 0.9998 - val_digit_4_accuracy: 1.0000\n",
      "Epoch 33/60\n",
      "2800/2800 [==============================] - 386s 138ms/step - loss: 0.0125 - digit_0_loss: 0.0039 - digit_1_loss: 0.0030 - digit_2_loss: 0.0022 - digit_3_loss: 0.0020 - digit_4_loss: 0.0015 - digit_0_accuracy: 0.9990 - digit_1_accuracy: 0.9993 - digit_2_accuracy: 0.9994 - digit_3_accuracy: 0.9995 - digit_4_accuracy: 0.9996 - val_loss: 0.0448 - val_digit_0_loss: 0.0033 - val_digit_1_loss: 0.0183 - val_digit_2_loss: 0.0229 - val_digit_3_loss: 2.7048e-04 - val_digit_4_loss: 5.0170e-08 - val_digit_0_accuracy: 0.9998 - val_digit_1_accuracy: 0.9991 - val_digit_2_accuracy: 0.9993 - val_digit_3_accuracy: 0.9998 - val_digit_4_accuracy: 1.0000\n",
      "Epoch 34/60\n",
      "2800/2800 [==============================] - 386s 138ms/step - loss: 0.0122 - digit_0_loss: 0.0039 - digit_1_loss: 0.0028 - digit_2_loss: 0.0023 - digit_3_loss: 0.0020 - digit_4_loss: 0.0012 - digit_0_accuracy: 0.9990 - digit_1_accuracy: 0.9993 - digit_2_accuracy: 0.9994 - digit_3_accuracy: 0.9995 - digit_4_accuracy: 0.9997 - val_loss: 0.0428 - val_digit_0_loss: 0.0037 - val_digit_1_loss: 0.0186 - val_digit_2_loss: 0.0202 - val_digit_3_loss: 2.9040e-04 - val_digit_4_loss: 1.2951e-06 - val_digit_0_accuracy: 0.9996 - val_digit_1_accuracy: 0.9991 - val_digit_2_accuracy: 0.9991 - val_digit_3_accuracy: 0.9998 - val_digit_4_accuracy: 1.0000\n",
      "Epoch 35/60\n",
      "2800/2800 [==============================] - 385s 137ms/step - loss: 0.0120 - digit_0_loss: 0.0039 - digit_1_loss: 0.0030 - digit_2_loss: 0.0021 - digit_3_loss: 0.0018 - digit_4_loss: 0.0012 - digit_0_accuracy: 0.9991 - digit_1_accuracy: 0.9993 - digit_2_accuracy: 0.9995 - digit_3_accuracy: 0.9996 - digit_4_accuracy: 0.9996 - val_loss: 0.0440 - val_digit_0_loss: 0.0033 - val_digit_1_loss: 0.0191 - val_digit_2_loss: 0.0206 - val_digit_3_loss: 9.5369e-04 - val_digit_4_loss: 3.4976e-07 - val_digit_0_accuracy: 0.9998 - val_digit_1_accuracy: 0.9989 - val_digit_2_accuracy: 0.9993 - val_digit_3_accuracy: 0.9998 - val_digit_4_accuracy: 1.0000\n",
      "Epoch 36/60\n",
      "2800/2800 [==============================] - 385s 138ms/step - loss: 0.0114 - digit_0_loss: 0.0043 - digit_1_loss: 0.0023 - digit_2_loss: 0.0022 - digit_3_loss: 0.0015 - digit_4_loss: 0.0012 - digit_0_accuracy: 0.9990 - digit_1_accuracy: 0.9994 - digit_2_accuracy: 0.9995 - digit_3_accuracy: 0.9996 - digit_4_accuracy: 0.9997 - val_loss: 0.0464 - val_digit_0_loss: 0.0037 - val_digit_1_loss: 0.0166 - val_digit_2_loss: 0.0253 - val_digit_3_loss: 8.3140e-04 - val_digit_4_loss: 7.3083e-06 - val_digit_0_accuracy: 0.9996 - val_digit_1_accuracy: 0.9989 - val_digit_2_accuracy: 0.9993 - val_digit_3_accuracy: 0.9998 - val_digit_4_accuracy: 1.0000\n",
      "Epoch 37/60\n",
      "2800/2800 [==============================] - 385s 138ms/step - loss: 0.0109 - digit_0_loss: 0.0035 - digit_1_loss: 0.0022 - digit_2_loss: 0.0020 - digit_3_loss: 0.0020 - digit_4_loss: 0.0011 - digit_0_accuracy: 0.9991 - digit_1_accuracy: 0.9994 - digit_2_accuracy: 0.9995 - digit_3_accuracy: 0.9996 - digit_4_accuracy: 0.9997 - val_loss: 0.0400 - val_digit_0_loss: 0.0030 - val_digit_1_loss: 0.0119 - val_digit_2_loss: 0.0247 - val_digit_3_loss: 4.2993e-04 - val_digit_4_loss: 4.6676e-07 - val_digit_0_accuracy: 0.9998 - val_digit_1_accuracy: 0.9987 - val_digit_2_accuracy: 0.9993 - val_digit_3_accuracy: 0.9998 - val_digit_4_accuracy: 1.0000\n",
      "Epoch 38/60\n",
      "2800/2800 [==============================] - 385s 137ms/step - loss: 0.0108 - digit_0_loss: 0.0034 - digit_1_loss: 0.0022 - digit_2_loss: 0.0022 - digit_3_loss: 0.0016 - digit_4_loss: 0.0014 - digit_0_accuracy: 0.9991 - digit_1_accuracy: 0.9995 - digit_2_accuracy: 0.9995 - digit_3_accuracy: 0.9996 - digit_4_accuracy: 0.9996 - val_loss: 0.0451 - val_digit_0_loss: 0.0036 - val_digit_1_loss: 0.0172 - val_digit_2_loss: 0.0239 - val_digit_3_loss: 3.9645e-04 - val_digit_4_loss: 4.7629e-06 - val_digit_0_accuracy: 0.9996 - val_digit_1_accuracy: 0.9989 - val_digit_2_accuracy: 0.9993 - val_digit_3_accuracy: 0.9998 - val_digit_4_accuracy: 1.0000\n",
      "Epoch 39/60\n",
      "2800/2800 [==============================] - 382s 136ms/step - loss: 0.0110 - digit_0_loss: 0.0035 - digit_1_loss: 0.0026 - digit_2_loss: 0.0018 - digit_3_loss: 0.0019 - digit_4_loss: 0.0011 - digit_0_accuracy: 0.9991 - digit_1_accuracy: 0.9994 - digit_2_accuracy: 0.9995 - digit_3_accuracy: 0.9995 - digit_4_accuracy: 0.9997 - val_loss: 0.0447 - val_digit_0_loss: 0.0033 - val_digit_1_loss: 0.0178 - val_digit_2_loss: 0.0235 - val_digit_3_loss: 6.4430e-05 - val_digit_4_loss: 3.1957e-07 - val_digit_0_accuracy: 0.9998 - val_digit_1_accuracy: 0.9987 - val_digit_2_accuracy: 0.9993 - val_digit_3_accuracy: 1.0000 - val_digit_4_accuracy: 1.0000\n",
      "Epoch 40/60\n",
      "2800/2800 [==============================] - 383s 137ms/step - loss: 0.0102 - digit_0_loss: 0.0034 - digit_1_loss: 0.0021 - digit_2_loss: 0.0018 - digit_3_loss: 0.0017 - digit_4_loss: 0.0012 - digit_0_accuracy: 0.9991 - digit_1_accuracy: 0.9995 - digit_2_accuracy: 0.9995 - digit_3_accuracy: 0.9996 - digit_4_accuracy: 0.9997 - val_loss: 0.0452 - val_digit_0_loss: 0.0037 - val_digit_1_loss: 0.0148 - val_digit_2_loss: 0.0261 - val_digit_3_loss: 5.3636e-04 - val_digit_4_loss: 3.7075e-07 - val_digit_0_accuracy: 0.9998 - val_digit_1_accuracy: 0.9991 - val_digit_2_accuracy: 0.9991 - val_digit_3_accuracy: 0.9996 - val_digit_4_accuracy: 1.0000\n",
      "Epoch 41/60\n",
      "2800/2800 [==============================] - 384s 137ms/step - loss: 0.0099 - digit_0_loss: 0.0030 - digit_1_loss: 0.0023 - digit_2_loss: 0.0020 - digit_3_loss: 0.0016 - digit_4_loss: 9.9418e-04 - digit_0_accuracy: 0.9993 - digit_1_accuracy: 0.9994 - digit_2_accuracy: 0.9995 - digit_3_accuracy: 0.9996 - digit_4_accuracy: 0.9997 - val_loss: 0.0445 - val_digit_0_loss: 0.0039 - val_digit_1_loss: 0.0159 - val_digit_2_loss: 0.0245 - val_digit_3_loss: 2.4971e-04 - val_digit_4_loss: 3.3817e-06 - val_digit_0_accuracy: 0.9998 - val_digit_1_accuracy: 0.9993 - val_digit_2_accuracy: 0.9993 - val_digit_3_accuracy: 0.9998 - val_digit_4_accuracy: 1.0000\n",
      "Epoch 42/60\n",
      "2800/2800 [==============================] - 384s 137ms/step - loss: 0.0100 - digit_0_loss: 0.0032 - digit_1_loss: 0.0021 - digit_2_loss: 0.0021 - digit_3_loss: 0.0015 - digit_4_loss: 0.0011 - digit_0_accuracy: 0.9991 - digit_1_accuracy: 0.9995 - digit_2_accuracy: 0.9995 - digit_3_accuracy: 0.9995 - digit_4_accuracy: 0.9997 - val_loss: 0.0407 - val_digit_0_loss: 0.0043 - val_digit_1_loss: 0.0098 - val_digit_2_loss: 0.0258 - val_digit_3_loss: 7.5215e-04 - val_digit_4_loss: 1.3646e-07 - val_digit_0_accuracy: 0.9996 - val_digit_1_accuracy: 0.9987 - val_digit_2_accuracy: 0.9989 - val_digit_3_accuracy: 0.9995 - val_digit_4_accuracy: 1.0000\n",
      "Epoch 43/60\n",
      "2800/2800 [==============================] - ETA: 0s - loss: 0.0099 - digit_0_loss: 0.0034 - digit_1_loss: 0.0022 - digit_2_loss: 0.0020 - digit_3_loss: 0.0013 - digit_4_loss: 9.7230e-04 - digit_0_accuracy: 0.9992 - digit_1_accuracy: 0.9994 - digit_2_accuracy: 0.9995 - digit_3_accuracy: 0.9996 - digit_4_accuracy: 0.9997\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
      "2800/2800 [==============================] - 382s 137ms/step - loss: 0.0099 - digit_0_loss: 0.0034 - digit_1_loss: 0.0022 - digit_2_loss: 0.0020 - digit_3_loss: 0.0013 - digit_4_loss: 9.7230e-04 - digit_0_accuracy: 0.9992 - digit_1_accuracy: 0.9994 - digit_2_accuracy: 0.9995 - digit_3_accuracy: 0.9996 - digit_4_accuracy: 0.9997 - val_loss: 0.0433 - val_digit_0_loss: 0.0033 - val_digit_1_loss: 0.0159 - val_digit_2_loss: 0.0235 - val_digit_3_loss: 6.3201e-04 - val_digit_4_loss: 1.8030e-08 - val_digit_0_accuracy: 0.9998 - val_digit_1_accuracy: 0.9993 - val_digit_2_accuracy: 0.9993 - val_digit_3_accuracy: 0.9998 - val_digit_4_accuracy: 1.0000\n",
      "Epoch 44/60\n",
      "2800/2800 [==============================] - 382s 136ms/step - loss: 0.0091 - digit_0_loss: 0.0030 - digit_1_loss: 0.0019 - digit_2_loss: 0.0015 - digit_3_loss: 0.0014 - digit_4_loss: 0.0013 - digit_0_accuracy: 0.9992 - digit_1_accuracy: 0.9995 - digit_2_accuracy: 0.9996 - digit_3_accuracy: 0.9996 - digit_4_accuracy: 0.9997 - val_loss: 0.0449 - val_digit_0_loss: 0.0035 - val_digit_1_loss: 0.0173 - val_digit_2_loss: 0.0237 - val_digit_3_loss: 3.1594e-04 - val_digit_4_loss: 1.2197e-07 - val_digit_0_accuracy: 0.9998 - val_digit_1_accuracy: 0.9991 - val_digit_2_accuracy: 0.9991 - val_digit_3_accuracy: 0.9998 - val_digit_4_accuracy: 1.0000\n",
      "Epoch 45/60\n",
      "2800/2800 [==============================] - 383s 137ms/step - loss: 0.0083 - digit_0_loss: 0.0027 - digit_1_loss: 0.0018 - digit_2_loss: 0.0013 - digit_3_loss: 0.0014 - digit_4_loss: 9.8069e-04 - digit_0_accuracy: 0.9993 - digit_1_accuracy: 0.9995 - digit_2_accuracy: 0.9996 - digit_3_accuracy: 0.9996 - digit_4_accuracy: 0.9997 - val_loss: 0.0429 - val_digit_0_loss: 0.0035 - val_digit_1_loss: 0.0156 - val_digit_2_loss: 0.0235 - val_digit_3_loss: 2.9540e-04 - val_digit_4_loss: 6.0892e-07 - val_digit_0_accuracy: 0.9996 - val_digit_1_accuracy: 0.9991 - val_digit_2_accuracy: 0.9989 - val_digit_3_accuracy: 0.9998 - val_digit_4_accuracy: 1.0000\n",
      "Epoch 46/60\n",
      "2800/2800 [==============================] - 384s 137ms/step - loss: 0.0079 - digit_0_loss: 0.0028 - digit_1_loss: 0.0015 - digit_2_loss: 0.0014 - digit_3_loss: 0.0012 - digit_4_loss: 9.2065e-04 - digit_0_accuracy: 0.9993 - digit_1_accuracy: 0.9996 - digit_2_accuracy: 0.9997 - digit_3_accuracy: 0.9997 - digit_4_accuracy: 0.9998 - val_loss: 0.0428 - val_digit_0_loss: 0.0033 - val_digit_1_loss: 0.0166 - val_digit_2_loss: 0.0228 - val_digit_3_loss: 2.0076e-04 - val_digit_4_loss: 8.5974e-08 - val_digit_0_accuracy: 0.9998 - val_digit_1_accuracy: 0.9991 - val_digit_2_accuracy: 0.9991 - val_digit_3_accuracy: 0.9998 - val_digit_4_accuracy: 1.0000\n",
      "Epoch 47/60\n",
      "2800/2800 [==============================] - 382s 137ms/step - loss: 0.0075 - digit_0_loss: 0.0025 - digit_1_loss: 0.0017 - digit_2_loss: 0.0014 - digit_3_loss: 0.0011 - digit_4_loss: 8.5732e-04 - digit_0_accuracy: 0.9994 - digit_1_accuracy: 0.9996 - digit_2_accuracy: 0.9996 - digit_3_accuracy: 0.9997 - digit_4_accuracy: 0.9997 - val_loss: 0.0460 - val_digit_0_loss: 0.0034 - val_digit_1_loss: 0.0168 - val_digit_2_loss: 0.0255 - val_digit_3_loss: 2.9413e-04 - val_digit_4_loss: 2.6439e-08 - val_digit_0_accuracy: 0.9998 - val_digit_1_accuracy: 0.9991 - val_digit_2_accuracy: 0.9989 - val_digit_3_accuracy: 0.9998 - val_digit_4_accuracy: 1.0000\n",
      "Epoch 48/60\n",
      "2800/2800 [==============================] - 383s 137ms/step - loss: 0.0077 - digit_0_loss: 0.0027 - digit_1_loss: 0.0016 - digit_2_loss: 0.0015 - digit_3_loss: 0.0011 - digit_4_loss: 8.0489e-04 - digit_0_accuracy: 0.9993 - digit_1_accuracy: 0.9996 - digit_2_accuracy: 0.9996 - digit_3_accuracy: 0.9997 - digit_4_accuracy: 0.9998 - val_loss: 0.0430 - val_digit_0_loss: 0.0035 - val_digit_1_loss: 0.0152 - val_digit_2_loss: 0.0240 - val_digit_3_loss: 3.2424e-04 - val_digit_4_loss: 1.1857e-08 - val_digit_0_accuracy: 0.9998 - val_digit_1_accuracy: 0.9991 - val_digit_2_accuracy: 0.9991 - val_digit_3_accuracy: 0.9998 - val_digit_4_accuracy: 1.0000\n",
      "Epoch 49/60\n",
      "2800/2800 [==============================] - ETA: 0s - loss: 0.0079 - digit_0_loss: 0.0028 - digit_1_loss: 0.0015 - digit_2_loss: 0.0015 - digit_3_loss: 0.0012 - digit_4_loss: 8.6188e-04 - digit_0_accuracy: 0.9993 - digit_1_accuracy: 0.9996 - digit_2_accuracy: 0.9996 - digit_3_accuracy: 0.9997 - digit_4_accuracy: 0.9998\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 8.100000013655517e-06.\n",
      "2800/2800 [==============================] - 384s 137ms/step - loss: 0.0079 - digit_0_loss: 0.0028 - digit_1_loss: 0.0015 - digit_2_loss: 0.0015 - digit_3_loss: 0.0012 - digit_4_loss: 8.6188e-04 - digit_0_accuracy: 0.9993 - digit_1_accuracy: 0.9996 - digit_2_accuracy: 0.9996 - digit_3_accuracy: 0.9997 - digit_4_accuracy: 0.9998 - val_loss: 0.0424 - val_digit_0_loss: 0.0035 - val_digit_1_loss: 0.0157 - val_digit_2_loss: 0.0232 - val_digit_3_loss: 1.2006e-04 - val_digit_4_loss: 1.1221e-07 - val_digit_0_accuracy: 0.9998 - val_digit_1_accuracy: 0.9989 - val_digit_2_accuracy: 0.9991 - val_digit_3_accuracy: 1.0000 - val_digit_4_accuracy: 1.0000\n",
      "Epoch 50/60\n",
      "2800/2800 [==============================] - 384s 137ms/step - loss: 0.0072 - digit_0_loss: 0.0023 - digit_1_loss: 0.0017 - digit_2_loss: 0.0013 - digit_3_loss: 0.0013 - digit_4_loss: 7.0102e-04 - digit_0_accuracy: 0.9994 - digit_1_accuracy: 0.9996 - digit_2_accuracy: 0.9996 - digit_3_accuracy: 0.9997 - digit_4_accuracy: 0.9998 - val_loss: 0.0414 - val_digit_0_loss: 0.0034 - val_digit_1_loss: 0.0155 - val_digit_2_loss: 0.0224 - val_digit_3_loss: 1.9509e-04 - val_digit_4_loss: 9.6590e-08 - val_digit_0_accuracy: 0.9998 - val_digit_1_accuracy: 0.9989 - val_digit_2_accuracy: 0.9991 - val_digit_3_accuracy: 0.9998 - val_digit_4_accuracy: 1.0000\n",
      "Epoch 51/60\n",
      "2800/2800 [==============================] - 383s 137ms/step - loss: 0.0073 - digit_0_loss: 0.0023 - digit_1_loss: 0.0016 - digit_2_loss: 0.0015 - digit_3_loss: 0.0010 - digit_4_loss: 8.7192e-04 - digit_0_accuracy: 0.9993 - digit_1_accuracy: 0.9996 - digit_2_accuracy: 0.9997 - digit_3_accuracy: 0.9997 - digit_4_accuracy: 0.9998 - val_loss: 0.0411 - val_digit_0_loss: 0.0034 - val_digit_1_loss: 0.0150 - val_digit_2_loss: 0.0225 - val_digit_3_loss: 2.2233e-04 - val_digit_4_loss: 1.1829e-07 - val_digit_0_accuracy: 0.9998 - val_digit_1_accuracy: 0.9989 - val_digit_2_accuracy: 0.9991 - val_digit_3_accuracy: 0.9998 - val_digit_4_accuracy: 1.0000\n",
      "Epoch 52/60\n",
      "2800/2800 [==============================] - 382s 136ms/step - loss: 0.0072 - digit_0_loss: 0.0021 - digit_1_loss: 0.0017 - digit_2_loss: 0.0014 - digit_3_loss: 0.0013 - digit_4_loss: 7.6299e-04 - digit_0_accuracy: 0.9994 - digit_1_accuracy: 0.9996 - digit_2_accuracy: 0.9997 - digit_3_accuracy: 0.9997 - digit_4_accuracy: 0.9998 - val_loss: 0.0401 - val_digit_0_loss: 0.0034 - val_digit_1_loss: 0.0142 - val_digit_2_loss: 0.0224 - val_digit_3_loss: 2.2634e-04 - val_digit_4_loss: 7.1221e-08 - val_digit_0_accuracy: 0.9998 - val_digit_1_accuracy: 0.9991 - val_digit_2_accuracy: 0.9991 - val_digit_3_accuracy: 0.9998 - val_digit_4_accuracy: 1.0000\n",
      "Epoch 53/60\n",
      "2800/2800 [==============================] - 384s 137ms/step - loss: 0.0070 - digit_0_loss: 0.0022 - digit_1_loss: 0.0016 - digit_2_loss: 0.0012 - digit_3_loss: 9.9851e-04 - digit_4_loss: 9.7749e-04 - digit_0_accuracy: 0.9994 - digit_1_accuracy: 0.9996 - digit_2_accuracy: 0.9997 - digit_3_accuracy: 0.9997 - digit_4_accuracy: 0.9998 - val_loss: 0.0389 - val_digit_0_loss: 0.0033 - val_digit_1_loss: 0.0134 - val_digit_2_loss: 0.0219 - val_digit_3_loss: 2.3545e-04 - val_digit_4_loss: 7.9780e-08 - val_digit_0_accuracy: 0.9998 - val_digit_1_accuracy: 0.9991 - val_digit_2_accuracy: 0.9991 - val_digit_3_accuracy: 0.9998 - val_digit_4_accuracy: 1.0000\n",
      "Epoch 54/60\n",
      "2800/2800 [==============================] - 386s 138ms/step - loss: 0.0071 - digit_0_loss: 0.0024 - digit_1_loss: 0.0016 - digit_2_loss: 0.0014 - digit_3_loss: 0.0011 - digit_4_loss: 6.6554e-04 - digit_0_accuracy: 0.9994 - digit_1_accuracy: 0.9996 - digit_2_accuracy: 0.9996 - digit_3_accuracy: 0.9997 - digit_4_accuracy: 0.9998 - val_loss: 0.0397 - val_digit_0_loss: 0.0033 - val_digit_1_loss: 0.0137 - val_digit_2_loss: 0.0225 - val_digit_3_loss: 2.0581e-04 - val_digit_4_loss: 1.7899e-07 - val_digit_0_accuracy: 0.9998 - val_digit_1_accuracy: 0.9991 - val_digit_2_accuracy: 0.9991 - val_digit_3_accuracy: 0.9998 - val_digit_4_accuracy: 1.0000\n",
      "Epoch 55/60\n",
      "2800/2800 [==============================] - 385s 138ms/step - loss: 0.0076 - digit_0_loss: 0.0024 - digit_1_loss: 0.0019 - digit_2_loss: 0.0013 - digit_3_loss: 0.0012 - digit_4_loss: 7.8501e-04 - digit_0_accuracy: 0.9993 - digit_1_accuracy: 0.9995 - digit_2_accuracy: 0.9997 - digit_3_accuracy: 0.9997 - digit_4_accuracy: 0.9998 - val_loss: 0.0388 - val_digit_0_loss: 0.0033 - val_digit_1_loss: 0.0134 - val_digit_2_loss: 0.0219 - val_digit_3_loss: 1.7921e-04 - val_digit_4_loss: 2.2443e-07 - val_digit_0_accuracy: 0.9998 - val_digit_1_accuracy: 0.9991 - val_digit_2_accuracy: 0.9991 - val_digit_3_accuracy: 0.9998 - val_digit_4_accuracy: 1.0000\n",
      "Epoch 56/60\n",
      "2800/2800 [==============================] - 385s 137ms/step - loss: 0.0072 - digit_0_loss: 0.0021 - digit_1_loss: 0.0017 - digit_2_loss: 0.0013 - digit_3_loss: 0.0014 - digit_4_loss: 6.9549e-04 - digit_0_accuracy: 0.9994 - digit_1_accuracy: 0.9996 - digit_2_accuracy: 0.9997 - digit_3_accuracy: 0.9997 - digit_4_accuracy: 0.9998 - val_loss: 0.0397 - val_digit_0_loss: 0.0033 - val_digit_1_loss: 0.0145 - val_digit_2_loss: 0.0217 - val_digit_3_loss: 2.1393e-04 - val_digit_4_loss: 4.4246e-07 - val_digit_0_accuracy: 0.9998 - val_digit_1_accuracy: 0.9989 - val_digit_2_accuracy: 0.9991 - val_digit_3_accuracy: 0.9998 - val_digit_4_accuracy: 1.0000\n",
      "Epoch 57/60\n",
      "2800/2800 [==============================] - 385s 137ms/step - loss: 0.0069 - digit_0_loss: 0.0020 - digit_1_loss: 0.0017 - digit_2_loss: 0.0014 - digit_3_loss: 0.0011 - digit_4_loss: 7.3519e-04 - digit_0_accuracy: 0.9994 - digit_1_accuracy: 0.9996 - digit_2_accuracy: 0.9996 - digit_3_accuracy: 0.9997 - digit_4_accuracy: 0.9998 - val_loss: 0.0401 - val_digit_0_loss: 0.0033 - val_digit_1_loss: 0.0140 - val_digit_2_loss: 0.0226 - val_digit_3_loss: 1.4645e-04 - val_digit_4_loss: 1.2293e-07 - val_digit_0_accuracy: 0.9998 - val_digit_1_accuracy: 0.9989 - val_digit_2_accuracy: 0.9991 - val_digit_3_accuracy: 0.9998 - val_digit_4_accuracy: 1.0000\n",
      "Epoch 58/60\n",
      "2800/2800 [==============================] - 384s 137ms/step - loss: 0.0070 - digit_0_loss: 0.0021 - digit_1_loss: 0.0015 - digit_2_loss: 0.0014 - digit_3_loss: 0.0011 - digit_4_loss: 9.5564e-04 - digit_0_accuracy: 0.9994 - digit_1_accuracy: 0.9996 - digit_2_accuracy: 0.9997 - digit_3_accuracy: 0.9997 - digit_4_accuracy: 0.9998 - val_loss: 0.0386 - val_digit_0_loss: 0.0032 - val_digit_1_loss: 0.0134 - val_digit_2_loss: 0.0218 - val_digit_3_loss: 1.2250e-04 - val_digit_4_loss: 6.2017e-07 - val_digit_0_accuracy: 0.9998 - val_digit_1_accuracy: 0.9989 - val_digit_2_accuracy: 0.9991 - val_digit_3_accuracy: 1.0000 - val_digit_4_accuracy: 1.0000\n",
      "Epoch 59/60\n",
      "2800/2800 [==============================] - 382s 137ms/step - loss: 0.0065 - digit_0_loss: 0.0024 - digit_1_loss: 0.0015 - digit_2_loss: 0.0011 - digit_3_loss: 9.7056e-04 - digit_4_loss: 6.4813e-04 - digit_0_accuracy: 0.9994 - digit_1_accuracy: 0.9996 - digit_2_accuracy: 0.9997 - digit_3_accuracy: 0.9998 - digit_4_accuracy: 0.9998 - val_loss: 0.0396 - val_digit_0_loss: 0.0033 - val_digit_1_loss: 0.0138 - val_digit_2_loss: 0.0224 - val_digit_3_loss: 1.6660e-04 - val_digit_4_loss: 2.0218e-07 - val_digit_0_accuracy: 0.9998 - val_digit_1_accuracy: 0.9989 - val_digit_2_accuracy: 0.9991 - val_digit_3_accuracy: 0.9998 - val_digit_4_accuracy: 1.0000\n",
      "Epoch 60/60\n",
      "2800/2800 [==============================] - 382s 136ms/step - loss: 0.0069 - digit_0_loss: 0.0025 - digit_1_loss: 0.0013 - digit_2_loss: 0.0015 - digit_3_loss: 9.9579e-04 - digit_4_loss: 6.3607e-04 - digit_0_accuracy: 0.9994 - digit_1_accuracy: 0.9997 - digit_2_accuracy: 0.9996 - digit_3_accuracy: 0.9998 - digit_4_accuracy: 0.9998 - val_loss: 0.0384 - val_digit_0_loss: 0.0033 - val_digit_1_loss: 0.0124 - val_digit_2_loss: 0.0224 - val_digit_3_loss: 2.2585e-04 - val_digit_4_loss: 2.5806e-07 - val_digit_0_accuracy: 0.9998 - val_digit_1_accuracy: 0.9991 - val_digit_2_accuracy: 0.9991 - val_digit_3_accuracy: 0.9998 - val_digit_4_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "model = cnn_model(input_dim=(128, 128, 1))                         #define cnn model\n",
    "history = model.fit(\n",
    "    data_augmentor(Train),                                         #training data\n",
    "    validation_data = (x_val, [y_val[:,i] for i in range(5)]),     #validtion data\n",
    "    batch_size = batchsize,                                        #batchsize=128\n",
    "    epochs = 60,                                                   #number of epoch\n",
    "    steps_per_epoch=len(X_train)/20,                               \n",
    "    callbacks = [reduce_lr, model_checkpoint_callback],            #callbacks\n",
    "    verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZgJkvbsxQ6jw"
   },
   "source": [
    "convert back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "If9mvBYF5nQs"
   },
   "outputs": [],
   "source": [
    "def onehot_to_label(arr):       #convert back\n",
    "    arr = np.array(arr)\n",
    "    R = np.argmax(arr, axis=2)  #select the label\n",
    "    R = np.transpose(R)\n",
    "    return R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zu3NgYD9RG1n"
   },
   "source": [
    "write the result in csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bGJEel9C5oyk"
   },
   "outputs": [],
   "source": [
    "def write_to_csv(prediction):\n",
    "    preds = onehot_to_label(prediction)                       #convert label\n",
    "    predss = [[i, ''.join(str(x) for x in pred)] for i, pred in enumerate(preds)]    #form the prediction\n",
    "    filename = \"sample.csv\"                                   #download file\n",
    "    with open(filename, 'w', newline='') as csvfile:          #open file\n",
    "        csvwriter = csv.writer(csvfile, delimiter=',')        #write file\n",
    "        csvwriter.writerow([\"Id\", \"Label\"])                   #write the title\n",
    "        csvwriter.writerows(predss)                           #write the rows(all the data)\n",
    "    files.download('sample.csv')                              #download file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DqpXnXxeRTvn"
   },
   "source": [
    "save model and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "Q9QWqJP95qde",
    "outputId": "bba281e8-f499-4717-dfb8-03f83ca41949"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_68a7e89e-9f28-409d-a47f-3518b22f7512\", \"sample.csv\", 226900)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#model.save_weights('weights.h5', overwrite=True)\n",
    "#You may not want to run this. ------------------------------------------\n",
    "model1 = cnn_model(input_dim=(128, 128, 1))\n",
    "file = '/content/drive/My Drive/checkpoints2/weights.02.h5'\n",
    "model1.load_weights(file)                                     #load weights\n",
    "\n",
    "preds = model1.predict(Thex_test)                             #prediction\n",
    "write_to_csv(preds)                                           #write to csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b9BvF02-RW3N"
   },
   "source": [
    "plot graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 176
    },
    "id": "IJk6_g8T5uOT",
    "outputId": "82c137a4-0bdc-48cc-ee44-ec53e1f53019"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"history_dict = history.history\\nloss_values = history_dict['loss']\\nval_loss_values = history_dict['val_loss']\\naccuracy1 = history_dict['digit_0_accuracy']\\naccuracy2 = history_dict['digit_1_accuracy']\\naccuracy3 = history_dict['digit_2_accuracy']\\naccuracy4 = history_dict['digit_3_accuracy']\\naccuracy5 = history_dict['digit_4_accuracy']\\nval_accuracy1 = history_dict['val_digit_0_accuracy']\\nval_accuracy2 = history_dict['val_digit_1_accuracy']\\nval_accuracy3 = history_dict['val_digit_2_accuracy']\\nval_accuracy4 = history_dict['val_digit_3_accuracy']\\nval_accuracy5 = history_dict['val_digit_4_accuracy']\\n \\nepochs = range(1, len(loss_values) + 1)\\nfig, ax = plt.subplots(1, 2, figsize=(14, 6))\\n#\\n# Plot the model accuracy vs Epochs\\n#\\nax[0].plot(epochs, accuracy1, 'r', label='Training accuracy1')\\nax[0].plot(epochs, accuracy2, 'y', label='Training accuracy2')\\nax[0].plot(epochs, accuracy3, 'b', label='Training accuracy3')\\nax[0].plot(epochs, accuracy4, 'g', label='Training accuracy4')\\nax[0].plot(epochs, accuracy5, 'c', label='Training accuracy5')\\n\\nax[0].set_title('Training &amp; Validation Accuracy', fontsize=16)\\nax[0].set_xlabel('Epochs', fontsize=16)\\nax[0].set_ylabel('Accuracy', fontsize=16)\\nax[0].legend()\\n\\n\\n\\nax[0].plot(epochs, val_accuracy1, 'r', label='Training accuracy1')\\nax[0].plot(epochs, val_accuracy2, 'y', label='Training accuracy2')\\nax[0].plot(epochs, val_accuracy3, 'b', label='Training accuracy3')\\nax[0].plot(epochs, val_accuracy4, 'g', label='Training accuracy4')\\nax[0].plot(epochs, val_accuracy5, 'c', label='Training accuracy5')\\nax[0].set_title('Training &amp; Validation Accuracy', fontsize=16)\\nax[0].set_xlabel('Epochs', fontsize=16)\\nax[0].set_ylabel('Accuracy', fontsize=16)\\nax[0].legend()\\n\\n#\\n# Plot the loss vs Epochs\\n#\\nax[1].plot(epochs, loss_values, 'bo', label='Training loss') \\nax[1].plot(epochs, val_loss_values, 'b', label='Validation loss')\\nax[1].set_title('Training &amp; Validation Loss', fontsize=16)\\nax[1].set_xlabel('Epochs', fontsize=16)\\nax[1].set_ylabel('Loss', fontsize=16)\\nax[1].legend()\""
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "loss_values = history_dict['loss']\n",
    "val_loss_values = history_dict['val_loss']\n",
    "accuracy1 = history_dict['digit_0_accuracy']\n",
    "accuracy2 = history_dict['digit_1_accuracy']\n",
    "accuracy3 = history_dict['digit_2_accuracy']\n",
    "accuracy4 = history_dict['digit_3_accuracy']\n",
    "accuracy5 = history_dict['digit_4_accuracy']\n",
    "val_accuracy1 = history_dict['val_digit_0_accuracy']\n",
    "val_accuracy2 = history_dict['val_digit_1_accuracy']\n",
    "val_accuracy3 = history_dict['val_digit_2_accuracy']\n",
    "val_accuracy4 = history_dict['val_digit_3_accuracy']\n",
    "val_accuracy5 = history_dict['val_digit_4_accuracy']\n",
    " \n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "fig, ax = plt.subplots(1, 3, figsize=(18, 5))\n",
    "#\n",
    "# Plot the model accuracy vs Epochs\n",
    "#\n",
    "ax[0].plot(epochs, accuracy1, 'r', label='Training accuracy1')\n",
    "ax[0].plot(epochs, accuracy2, 'y', label='Training accuracy2')\n",
    "ax[0].plot(epochs, accuracy3, 'b', label='Training accuracy3')\n",
    "ax[0].plot(epochs, accuracy4, 'g', label='Training accuracy4')\n",
    "ax[0].plot(epochs, accuracy5, 'c', label='Training accuracy5')\n",
    "\n",
    "ax[0].set_title('Training Accuracy', fontsize=16)\n",
    "ax[0].set_xlabel('Epochs', fontsize=16)\n",
    "ax[0].set_ylabel('Accuracy', fontsize=16)\n",
    "ax[0].legend()\n",
    "\n",
    "\n",
    "ax[1].plot(epochs, val_accuracy1, 'r', label='Validaton accuracy1')\n",
    "ax[1].plot(epochs, val_accuracy2, 'y', label='Validaton accuracy2')\n",
    "ax[1].plot(epochs, val_accuracy3, 'b', label='Validaton accuracy3')\n",
    "ax[1].plot(epochs, val_accuracy4, 'g', label='Validaton accuracy4')\n",
    "ax[1].plot(epochs, val_accuracy5, 'c', label='Validaton accuracy5')\n",
    "ax[1].set_title('Validation Accuracy', fontsize=16)\n",
    "ax[1].set_xlabel('Epochs', fontsize=16)\n",
    "ax[1].set_ylabel('Accuracy', fontsize=16)\n",
    "ax[1].legend()\n",
    "\n",
    "#\n",
    "# Plot the loss vs Epochs\n",
    "#\n",
    "ax[2].plot(epochs, loss_values, 'b', label='Training loss') \n",
    "ax[2].plot(epochs, val_loss_values, 'r', label='Validation loss')\n",
    "ax[2].set_title('Training & Validation Cross-Entropy Loss', fontsize=16)\n",
    "ax[2].set_xlabel('Epochs', fontsize=16)\n",
    "ax[2].set_ylabel('Loss', fontsize=16)\n",
    "ax[2].legend()\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f9W7H6Ku7uw0"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "A3_final1true.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
